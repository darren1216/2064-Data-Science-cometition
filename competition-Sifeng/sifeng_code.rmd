---
title: "competition"
author: "Sifeng Liang"
date: "2021/3/29"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(caret)
library(dplyr)
library(tidyr)
library(ggplot2)
library(corrplot)
library(fpp2)
library(tseries)
library(gridExtra)
library(forecast)
library(timetk)
library(RColorBrewer)
library(randomForest)
library(tree)
library(partykit)
library(rpart)
library(rpart.plot)
library(kernlab)
library(e1071)
library(mlbench)
library(ipred)
library(MASS)
library(elasticnet)
library(lars)
library(pls)
library(bnstruct)
library(outliers)
library(nnet)
library(forecast)
library(ipred)
library(outliers)
library(earth)

library(tidyverse)
library(caret)
library(modelr)
options(na.action = na.warn)  # turn on warnings for missing values
library(e1071) # needed for the skewness function
library(corrplot) # needed for the corrplot function
library(rjson)
library(data.table)
```

```{r}
# read the train set
train <- fread('C:\\Users\\SIFENG\\OneDrive - University of Pittsburgh\\Desktop\\Pitt\\2021 Spring\\IE-2064 DATA SCIENCE\\Competition\\Data\\competition-train.csv', stringsAsFactors=F, nrows=N_read)

# read the test set
test <- fread('C:\\Users\\SIFENG\\OneDrive - University of Pittsburgh\\Desktop\\Pitt\\2021 Spring\\IE-2064 DATA SCIENCE\\Competition\\Data\\competition-test-x-values.csv', stringsAsFactors=F, nrows=N_read)

# read the validation set
validation <- fread('C:\\Users\\SIFENG\\OneDrive - University of Pittsburgh\\Desktop\\Pitt\\2021 Spring\\IE-2064 DATA SCIENCE\\Competition\\Data\\competition-validation.csv', stringsAsFactors=F, nrows=N_read)
```

```{r}
# descriptive statistics
mean(train[["outcome"]])
median(train[["outcome"]])
quantile(train[["outcome"]])
range(train[["outcome"]])
```

```{r}
# Density plot to see distribution
ggplot(train, aes(x = outcome)) + geom_density()
```

```{r}
# idetify and remove outliers
par(mfrow = c(1, 2))
boxplot(train$outcome) # still have outliers
train <- subset(train,!(train$outcome > quantile(train$outcome, probs = c(.01, .995))[2]) | train$outcome < quantile(train$outcome, probs = c(.01, .995))[1])
boxplot(train$outcome) # outliers were removed
```


```{r}
# determine the level of skewness
engine.displ <- skewness(train$outcome)
engine.displ
# since the skewness coefficient is -3.36, the variable "outcome" is highly left-skewed.

# transform using Log10 transform

```

```{r}
tr = data.frame(train)
tr <- as_tibble(train)
predictor_raw <- tr[, 2:22]
outcome_raw <- as.matrix(tr$outcome)
predictor_imputed <- knn.impute(as.matrix(predictor_raw), k = 10)
```


```{r echo = FALSE, message = FALSE, warning = FALSE}
lowVariance <- nearZeroVar(predictor_imputed, names = TRUE)
head(lowVariance)
lowVariance <- nearZeroVar(predictor_imputed)

# Ignore columns with low variance
predictor_lower <- predictor_imputed[, -lowVariance]
```


```{r echo = FALSE, message = FALSE, warning = FALSE}
# Feature engineering
predictor_transf <- preProcess(predictor_imputed, method = c("center", "scale", "BoxCox"))
predictor_transf <- predict(predictor_transf, predictor_imputed)
```

```{r}
training <- createDataPartition(outcome_raw, p = 0.5, list = FALSE)

# Train sets
train_predictor <- predictor_transf[training,]
train_outcome <- outcome_raw[-training]

# Test sets
test_predictor <- predictor_transf[-training,]
test_outcome <- outcome_raw[training]

# Create data frame
train_data <- as.data.frame(train_predictor)
```

```{r}
# Linear regression
data(train)
predictor_data <- data.frame(train_data)
set.seed(1)
ctrl = trainControl(method = "cv", number = 10)
lmFit <- train(train_predictor, train_outcome, prePrcess = c("center", "scale", "BoxCox"), method = "lm", trControl = ctrl)
RMSE(predict(lmFit, train_predictor), train_outcome)
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
# Ridge regression model
set.seed(1)
ctrl = trainControl(method = "cv", number = 10)
ridgeGrid <- data.frame(.lambda = seq(0, 0.2, length = 21))
ridgeRigFit <- train(train_predictor, train_outcome, method = "ridge", tuneGrid = ridgeGrid, trControl = ctrl)
RMSE(predict(ridgeRigFit, train_predictor), train_outcome)
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
# SVM model
set.seed(1)
ctrl = trainControl(method = "cv", number = 10)
svmFit <- train(train_predictor, train_outcome, method = "svmLinear", tuneLength = 8, epsilon = 0.01, trControl = ctrl)
# Calculate RMSE of the model
RMSE(predict(svmFit, train_predictor), train_outcome)
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
# MARS model
set.seed(1)
ctrl = trainControl(method = "cv", number = 10)
marsGrid <- expand.grid(.degree = 1, .nprune = c(20, 30, 40, 50))
marsFit <- train(train_predictor, train_outcome, method = "earth", tuneGrid = marsGrid, trControl = ctrl)
# Calculate RMSE of the model
RMSE(predict(marsFit, train_predictor), train_outcome)
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
# Neural Net
set.seed(1)
ctrl = trainControl(method = "cv", number = 10)
nnetGrid <- expand.grid(decay = c(0), size = c(3))
nnetTune <- train(train_predictor, train_outcome, method = "nnet", tuneGrid = nnetGrid, trControl = ctrl, linout = TRUE, trace = FALSE)
# Calculate RMSE of the model
RMSE(predict(nnetTune, train_predictor), train_outcome)
```

```{r echo = FALSE, message = FALSE, warning = FALSE}
# KNN model
set.seed(1)
ctrl = trainControl(method = "cv", number = 10)
knnFit <- train(train_predictor, train_outcome, method = "knn", trControl = ctrl, tuneLength = 15)
# Calculate RMSE of the model
RMSE(predict(knnFit, train_predictor), train_outcome)
```